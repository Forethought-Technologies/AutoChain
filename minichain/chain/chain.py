"""Base interface that all chains should implement."""
import time
from abc import ABC, abstractmethod
from typing import Any, Dict, Optional, Sequence, Tuple, List, Union

from pydantic import BaseModel

from minichain.agent.conversational_agent import ConversationalAgent
from minichain.chain import constants
from minichain.errors import ToolRunningError
from minichain.memory.base import BaseMemory
from minichain.structs import AgentAction, AgentFinish
from minichain.tools.base import Tool
from minichain.tools.tools import HandOffToAgent


class BaseChain(BaseModel, ABC):
    """Base interface that all chains should implement."""

    memory: Optional[BaseMemory] = None
    verbosity: str = ""
    agent: ConversationalAgent
    tools: Sequence[Tool]

    @property
    def _chain_type(self) -> str:
        raise NotImplementedError("Saving not supported for this chain type.")

    @abstractmethod
    def _run(
        self,
        inputs: Dict[str, Any],
    ) -> AgentFinish:
        """Run the logic of this chain and return the output."""

    def run(
        self,
        user_query: str,
        return_only_outputs: bool = False,
    ) -> Union[AgentFinish, Dict[str, Any]]:
        """Run the logic of this chain and add to output if desired.

        Args:
            user_query: user query
            return_only_outputs: boolean for whether to return only outputs in the
                response. If True, only new keys generated by this chain will be
                returned. If False, both input keys and new keys generated by this
                chain will be returned. Defaults to False.

        """
        inputs = self.prep_inputs(user_query)

        try:
            output = self._run(inputs)
        except (KeyboardInterrupt, Exception) as e:
            raise e

        return self.prep_output(inputs, output, return_only_outputs)

    def prep_inputs(self, user_query: str) -> Dict[str, str]:
        """Validate and prep inputs."""
        inputs = {
            "query": user_query,
        }
        if self.memory is not None:
            external_context = self.memory.load_conversation()
            inputs.update(external_context)
        return inputs

    def prep_output(
        self,
        inputs: Dict[str, str],
        output: AgentFinish,
        return_only_outputs: bool = False,
    ) -> Dict[str, Any]:
        """Validate and prep outputs."""
        output_dict = output.format_output()
        if self.memory is not None:
            self.memory.save_conversation(inputs=inputs, outputs=output_dict)
            self.memory.save_memory(key=constants.OBSERVATIONS, value=output.intermediate_steps)

        if return_only_outputs:
            return output_dict
        else:
            return {**inputs, **output_dict}


class Chain(BaseChain):
    return_intermediate_steps: bool = False
    max_iterations: Optional[int] = 15
    max_execution_time: Optional[float] = None
    handle_parsing_errors = True

    def _should_continue(self, iterations: int, time_elapsed: float) -> bool:
        if self.max_iterations is not None and iterations >= self.max_iterations:
            return False
        if (
            self.max_execution_time is not None
            and time_elapsed >= self.max_execution_time
        ):
            return False

        return True

    @staticmethod
    def handle_repeated_action(agent_action: AgentAction) -> AgentFinish:
        if agent_action.model_response:
            print(f"Action taken before: {agent_action.tool}, "
                  f"input: {agent_action.tool_input}")
            return AgentFinish(
                return_values={"output": agent_action.response},
                log=f"Action taken before: {agent_action.tool}, "
                    f"input: {agent_action.tool_input}"
            )
        else:
            return AgentFinish(
                return_values={"output": HandOffToAgent().run("")},
                log=f"Handing off to agent"
            )

    def _take_next_step(
        self,
        name_to_tool_map: Dict[str, Tool],
        inputs: Dict[str, str],
        intermediate_steps: List[AgentAction],
    ) -> (AgentFinish, AgentAction):
        try:
            # Call the LLM to see what to do.
            output = self.agent.plan(
                intermediate_steps,
                **inputs,
            )
        except Exception as e:
            if not self.handle_parsing_errors:
                raise e
            observation = f"Invalid or incomplete response due to {e}"
            print(observation)
            output = AgentFinish(
                return_values={"output": HandOffToAgent().run("")},
                log=observation
            )
            return output

        # If the tool chosen is the finishing tool, then we end and return.
        if isinstance(output, AgentFinish):
            return output

        if isinstance(output, AgentAction):
            observation = ""
            # Otherwise we lookup the tool
            if output.tool in name_to_tool_map:
                tool = name_to_tool_map[output.tool]

                # how to handle the case where same action with same input is taken before
                if output.tool_input == self.memory.load_memory(tool.name):
                    return self.handle_repeated_action(output)

                self.memory.save_memory(tool.name, output.tool_input)
                # We then call the tool on the tool input to get an observation
                try:
                    observation = tool.run(output.tool_input)
                except ToolRunningError as e:
                    new_agent_action = self.agent.fix_action_input(tool, output,
                                                                   error=str(e))
                    if new_agent_action.tool_input != output.tool_input:
                        observation = tool.run(output.tool_input)

            else:
                observation = f"Tool {output.tool} if not supported"

            output.observation = observation
            return output
        else:
            raise ValueError(f"Unsupported action: {type(output)}")

    def _run(
        self,
        inputs: Dict[str, Any],
    ) -> AgentFinish:
        """Run text through and get agent response."""
        # Construct a mapping of tool name to tool for easy lookup

        name_to_tool_map = {tool.name: tool for tool in self.tools}
        # We construct a mapping from each tool to a color, used for logging.
        # color_mapping = get_color_mapping(
        #     [tool.name for tool in self.tools], excluded_colors=["green"]
        # )

        intermediate_steps: List[AgentAction] = self.memory.load_memory(constants.OBSERVATIONS, [])
        # Let's start tracking the number of iterations and time elapsed
        iterations = 0
        time_elapsed = 0.0
        start_time = time.time()
        # We now enter the agent loop (until it returns something).
        while self._should_continue(iterations, time_elapsed):
            print(f"\nInputs: {inputs}\n Intermediate steps: {intermediate_steps}\n")
            next_step_output = self._take_next_step(
                name_to_tool_map,
                inputs,
                intermediate_steps,
            )
            if isinstance(next_step_output, AgentFinish):
                next_step_output.intermediate_steps = intermediate_steps
                return next_step_output

            intermediate_steps.append(next_step_output)
            iterations += 1
            time_elapsed = time.time() - start_time
        # force the termination
        output = AgentFinish(
            return_values={"output": "Agent stopped due to iteration limit or time limit."},
            log="",
            intermediate_steps=intermediate_steps
        )
        return output
